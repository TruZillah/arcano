def generate_llm_response(prompt: str, user_id: str) -> str:
    """
    Placeholder for real LLM integration.
    Replace this stub with actual model call.
    """
    return f"[User {user_id}] LLM says: You said '{prompt}'" 